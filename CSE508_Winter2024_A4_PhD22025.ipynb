{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/orchid/anaconda3/envs/tf_gpu/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, TrainingArguments, Trainer\n",
    "from torch.utils.data import Dataset\n",
    "from rouge_score import rouge_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:1\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available and which device is being used\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(568411, 2)\n",
      "(394956, 2)\n",
      "(10000, 2)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "reviews = pd.read_csv(\"Reviews.csv\")\n",
    "reviews = reviews.dropna().reset_index(drop = True)\n",
    "reviews = reviews[['Text', 'Summary']]\n",
    "print(reviews.shape)\n",
    "reviews = reviews.drop_duplicates()\n",
    "print(reviews.shape)\n",
    "reviews = reviews[0:10000].reset_index(drop = True)\n",
    "print(reviews.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>bought several vitality canned dog food produc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>product arrived labeled jumbo salted peanut pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>confection around century light pillowy citrus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>looking secret ingredient robitussin believe f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>great taffy great price wide assortment yummy ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text                Summary  \\\n",
       "0  I have bought several of the Vitality canned d...  Good Quality Dog Food   \n",
       "1  Product arrived labeled as Jumbo Salted Peanut...      Not as Advertised   \n",
       "2  This is a confection that has been around a fe...  \"Delight\" says it all   \n",
       "3  If you are looking for the secret ingredient i...         Cough Medicine   \n",
       "4  Great taffy at a great price.  There was a wid...            Great taffy   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  bought several vitality canned dog food produc...  \n",
       "1  product arrived labeled jumbo salted peanut pe...  \n",
       "2  confection around century light pillowy citrus...  \n",
       "3  looking secret ingredient robitussin believe f...  \n",
       "4  great taffy great price wide assortment yummy ...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def cleaning(data):\n",
    "    corpus = []\n",
    "    for i in range(0, len(data)):\n",
    "        sentence = re.sub('[^a-zA-Z]', ' ', str(data[i])) # d. Removing Special Characters\n",
    "        sentence = sentence.lower() # Lowering the text\n",
    "        sentence = sentence.split() # Tokenization\n",
    "        \n",
    "        # Remove blank space tokens\n",
    "        sentence = [word for word in sentence if word.strip()]  # Removes empty strings\n",
    "        \n",
    "        all_stopwords = stopwords.words('english') # Removing the stopwords\n",
    "        #all_stopwords.remove('not')\n",
    "        # e. Lemmatization\n",
    "        sentence = [lemmatizer.lemmatize(word) for word in sentence if not word in set(all_stopwords)]\n",
    "        sentence = ' '.join(sentence)\n",
    "        corpus.append(sentence)\n",
    "      \n",
    "    return corpus\n",
    "\n",
    "\n",
    "reviews['cleaned_text'] =  cleaning(reviews['Text'])\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7500, 2)\n",
      "(2500, 2)\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "train_data, test_data = train_test_split(reviews, test_size=0.25, random_state=42)\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the GPT-2 tokenizer and model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-medium\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2-medium\")\n",
    "\n",
    "# Set pad token to end of sequence token\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length=512):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data.iloc[idx]\n",
    "        input_text = item['Text']\n",
    "        target_text = item['Summary']\n",
    "        \n",
    "        input_encoding = self.tokenizer(input_text, max_length=self.max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "        target_encoding = self.tokenizer(target_text, max_length=self.max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "        \n",
    "        return {\n",
    "            'input_ids': input_encoding['input_ids'].squeeze(),\n",
    "            'attention_mask': input_encoding['attention_mask'].squeeze(),\n",
    "            'labels': target_encoding['input_ids'].squeeze()\n",
    "        }\n",
    "\n",
    "# Create instances of the custom dataset class for training and testing\n",
    "train_dataset = CustomDataset(train_data, tokenizer)\n",
    "test_dataset = CustomDataset(test_data, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers[torch] in /home/orchid/.local/lib/python3.10/site-packages (4.40.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.7.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/orchid/.local/lib/python3.10/site-packages (from transformers[torch]) (0.22.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/orchid/.local/lib/python3.10/site-packages (from transformers[torch]) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/orchid/.local/lib/python3.10/site-packages (from transformers[torch]) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/orchid/.local/lib/python3.10/site-packages (from transformers[torch]) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/orchid/.local/lib/python3.10/site-packages (from transformers[torch]) (2023.10.3)\n",
      "Requirement already satisfied: requests in /home/orchid/.local/lib/python3.10/site-packages (from transformers[torch]) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/orchid/.local/lib/python3.10/site-packages (from transformers[torch]) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/orchid/.local/lib/python3.10/site-packages (from transformers[torch]) (0.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/orchid/.local/lib/python3.10/site-packages (from transformers[torch]) (4.66.2)\n",
      "Requirement already satisfied: torch in /home/orchid/.local/lib/python3.10/site-packages (from transformers[torch]) (2.1.2)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /home/orchid/.local/lib/python3.10/site-packages (from transformers[torch]) (0.24.1)\n",
      "Requirement already satisfied: psutil in /usr/lib/python3/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/orchid/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/orchid/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.9.0)\n",
      "Requirement already satisfied: sympy in /usr/lib/python3/dist-packages (from torch->transformers[torch]) (1.9)\n",
      "Requirement already satisfied: networkx in /home/orchid/.local/lib/python3.10/site-packages (from torch->transformers[torch]) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/orchid/.local/lib/python3.10/site-packages (from torch->transformers[torch]) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/orchid/.local/lib/python3.10/site-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/orchid/.local/lib/python3.10/site-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/orchid/.local/lib/python3.10/site-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/orchid/.local/lib/python3.10/site-packages (from torch->transformers[torch]) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/orchid/.local/lib/python3.10/site-packages (from torch->transformers[torch]) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/orchid/.local/lib/python3.10/site-packages (from torch->transformers[torch]) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/orchid/.local/lib/python3.10/site-packages (from torch->transformers[torch]) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/orchid/.local/lib/python3.10/site-packages (from torch->transformers[torch]) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/orchid/.local/lib/python3.10/site-packages (from torch->transformers[torch]) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/orchid/.local/lib/python3.10/site-packages (from torch->transformers[torch]) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/orchid/.local/lib/python3.10/site-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/orchid/.local/lib/python3.10/site-packages (from torch->transformers[torch]) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/orchid/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch]) (12.3.101)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/orchid/.local/lib/python3.10/site-packages (from requests->transformers[torch]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers[torch]) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/orchid/.local/lib/python3.10/site-packages (from requests->transformers[torch]) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers[torch]) (2020.6.20)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/orchid/.local/lib/python3.10/site-packages (from jinja2->torch->transformers[torch]) (2.1.3)\n",
      "\u001b[33mDEPRECATION: distro-info 1.1build1 has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: python-debian 0.1.43ubuntu1 has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of python-debian or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 2&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 # Define training arguments</span>                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 2 training_args = TrainingArguments(                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>per_device_train_batch_size=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">8</span>,                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>num_train_epochs=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">20</span>,                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>learning_rate= <span style=\"color: #0000ff; text-decoration-color: #0000ff\">5e-5</span>,  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">#5e-5,</span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">125</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/orchid/anaconda3/envs/tf_gpu/lib/python3.9/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">training_args.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">160</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">5</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__post_init__</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1602 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> (                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1603 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.framework == <span style=\"color: #808000; text-decoration-color: #808000\">\"pt\"</span>                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1604 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> is_torch_available()                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1605 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.device.type != <span style=\"color: #808000; text-decoration-color: #808000\">\"cuda\"</span>)                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1606 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.device.type != <span style=\"color: #808000; text-decoration-color: #808000\">\"mlu\"</span>)                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1607 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.device.type != <span style=\"color: #808000; text-decoration-color: #808000\">\"npu\"</span>)                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1608 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.device.type != <span style=\"color: #808000; text-decoration-color: #808000\">\"xpu\"</span>)                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/orchid/anaconda3/envs/tf_gpu/lib/python3.9/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">training_args.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">209</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">4</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">device</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2091 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">The device used by this process.</span>                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2092 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2093 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>requires_backends(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, [<span style=\"color: #808000; text-decoration-color: #808000\">\"torch\"</span>])                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2094 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._setup_devices                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2095 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2096 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">@property</span>                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2097 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">n_gpu</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>):                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/orchid/anaconda3/envs/tf_gpu/lib/python3.9/site-packages/transformers/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">generic.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">63</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__get__</span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 60 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>attr = <span style=\"color: #808000; text-decoration-color: #808000\">\"__cached_\"</span> + <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.fget.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__name__</span>                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 61 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>cached = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">getattr</span>(obj, attr, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>)                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 62 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> cached <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 63 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>cached = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.fget(obj)                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 64 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">setattr</span>(obj, attr, cached)                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 65 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> cached                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 66 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/orchid/anaconda3/envs/tf_gpu/lib/python3.9/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">training_args.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">200</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_setup_devices</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1997 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>logger.info(<span style=\"color: #808000; text-decoration-color: #808000\">\"PyTorch: setting up devices\"</span>)                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1998 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> is_sagemaker_mp_enabled():                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1999 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> is_accelerate_available():                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2000 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ImportError</span>(                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2001 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">f\"Using the `Trainer` with `PyTorch` requires `accelerate&gt;={</span>ACCELERA  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2002 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"Please run `pip install transformers[torch]` or `pip install accele</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2003 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>)                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ImportError: </span>Using the `Trainer` with `PyTorch` requires `accelerate&gt;=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.21</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>`: Please run `pip install \n",
       "transformers<span style=\"font-weight: bold\">[</span>torch<span style=\"font-weight: bold\">]</span>` or `pip install accelerate -U`\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<cell line: 2>\u001b[0m:\u001b[94m2\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 1 \u001b[0m\u001b[2m# Define training arguments\u001b[0m                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 2 training_args = TrainingArguments(                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 3 \u001b[0m\u001b[2m│   \u001b[0mper_device_train_batch_size=\u001b[94m8\u001b[0m,                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 4 \u001b[0m\u001b[2m│   \u001b[0mnum_train_epochs=\u001b[94m20\u001b[0m,                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 5 \u001b[0m\u001b[2m│   \u001b[0mlearning_rate= \u001b[94m5e-5\u001b[0m,  \u001b[2m#5e-5,\u001b[0m                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m__init__\u001b[0m:\u001b[94m125\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/orchid/anaconda3/envs/tf_gpu/lib/python3.9/site-packages/transformers/\u001b[0m\u001b[1;33mtraining_args.py\u001b[0m:\u001b[94m160\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[94m5\u001b[0m in \u001b[92m__post_init__\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1602 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m (                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1603 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.framework == \u001b[33m\"\u001b[0m\u001b[33mpt\u001b[0m\u001b[33m\"\u001b[0m                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1604 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[95mand\u001b[0m is_torch_available()                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1605 \u001b[2m│   │   │   \u001b[0m\u001b[95mand\u001b[0m (\u001b[96mself\u001b[0m.device.type != \u001b[33m\"\u001b[0m\u001b[33mcuda\u001b[0m\u001b[33m\"\u001b[0m)                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1606 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[95mand\u001b[0m (\u001b[96mself\u001b[0m.device.type != \u001b[33m\"\u001b[0m\u001b[33mmlu\u001b[0m\u001b[33m\"\u001b[0m)                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1607 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[95mand\u001b[0m (\u001b[96mself\u001b[0m.device.type != \u001b[33m\"\u001b[0m\u001b[33mnpu\u001b[0m\u001b[33m\"\u001b[0m)                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1608 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[95mand\u001b[0m (\u001b[96mself\u001b[0m.device.type != \u001b[33m\"\u001b[0m\u001b[33mxpu\u001b[0m\u001b[33m\"\u001b[0m)                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/orchid/anaconda3/envs/tf_gpu/lib/python3.9/site-packages/transformers/\u001b[0m\u001b[1;33mtraining_args.py\u001b[0m:\u001b[94m209\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[94m4\u001b[0m in \u001b[92mdevice\u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2091 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33mThe device used by this process.\u001b[0m                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2092 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2093 \u001b[0m\u001b[2m│   │   \u001b[0mrequires_backends(\u001b[96mself\u001b[0m, [\u001b[33m\"\u001b[0m\u001b[33mtorch\u001b[0m\u001b[33m\"\u001b[0m])                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2094 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._setup_devices                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2095 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2096 \u001b[0m\u001b[2m│   \u001b[0m\u001b[1;95m@property\u001b[0m                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2097 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mn_gpu\u001b[0m(\u001b[96mself\u001b[0m):                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/orchid/anaconda3/envs/tf_gpu/lib/python3.9/site-packages/transformers/utils/\u001b[0m\u001b[1;33mgeneric.py\u001b[0m:\u001b[94m63\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m__get__\u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 60 \u001b[0m\u001b[2m│   │   \u001b[0mattr = \u001b[33m\"\u001b[0m\u001b[33m__cached_\u001b[0m\u001b[33m\"\u001b[0m + \u001b[96mself\u001b[0m.fget.\u001b[91m__name__\u001b[0m                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 61 \u001b[0m\u001b[2m│   │   \u001b[0mcached = \u001b[96mgetattr\u001b[0m(obj, attr, \u001b[94mNone\u001b[0m)                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 62 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m cached \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 63 \u001b[2m│   │   │   \u001b[0mcached = \u001b[96mself\u001b[0m.fget(obj)                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 64 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96msetattr\u001b[0m(obj, attr, cached)                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 65 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m cached                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 66 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/orchid/anaconda3/envs/tf_gpu/lib/python3.9/site-packages/transformers/\u001b[0m\u001b[1;33mtraining_args.py\u001b[0m:\u001b[94m200\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[94m0\u001b[0m in \u001b[92m_setup_devices\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1997 \u001b[0m\u001b[2m│   │   \u001b[0mlogger.info(\u001b[33m\"\u001b[0m\u001b[33mPyTorch: setting up devices\u001b[0m\u001b[33m\"\u001b[0m)                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1998 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m is_sagemaker_mp_enabled():                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1999 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m is_accelerate_available():                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2000 \u001b[2m│   │   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mImportError\u001b[0m(                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2001 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mUsing the `Trainer` with `PyTorch` requires `accelerate>=\u001b[0m\u001b[33m{\u001b[0mACCELERA  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2002 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mPlease run `pip install transformers[torch]` or `pip install accele\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2003 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m)                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mImportError: \u001b[0mUsing the `Trainer` with `PyTorch` requires `accelerate>=\u001b[1;36m0.21\u001b[0m.\u001b[1;36m0\u001b[0m`: Please run `pip install \n",
       "transformers\u001b[1m[\u001b[0mtorch\u001b[1m]\u001b[0m` or `pip install accelerate -U`\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=8,\n",
    "    num_train_epochs=20,\n",
    "    learning_rate= 5e-5,  #5e-5,\n",
    "    output_dir=\"./output\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=500,\n",
    ")\n",
    "\n",
    "# Define the evaluation function\n",
    "def compute_metrics(pred):\n",
    "    labels_ids = pred.label_ids\n",
    "    pred_ids = pred.predictions\n",
    "\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    labels_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "\n",
    "    # Initialize ROUGE scorer\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "    rouge_scores = {'rouge1': [], 'rouge2': [], 'rougeL': []}\n",
    "    for hypothesis, reference in zip(pred_str, labels_str):\n",
    "        scores = scorer.score(reference, hypothesis)\n",
    "\n",
    "        for metric in rouge_scores.keys():\n",
    "            rouge_scores[metric].append(scores[metric].fmeasure)\n",
    "\n",
    "    rouge_avg_scores = {metric: np.mean(scores) for metric, scores in rouge_scores.items()}\n",
    "    return rouge_avg_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/orchid/anaconda3/envs/tf_gpu/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/home/orchid/anaconda3/envs/tf_gpu/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='469' max='469' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [469/469 03:45, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=469, training_loss=0.11479628670698544, metrics={'train_runtime': 227.3539, 'train_samples_per_second': 32.988, 'train_steps_per_second': 2.063, 'total_flos': 1959690240000000.0, 'train_loss': 0.11479628670698544, 'epoch': 1.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the Trainer instance\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully at: ./saved_model\n"
     ]
    }
   ],
   "source": [
    "# Define the directory path where you want to save the model\n",
    "output_dir = \"./saved_model\"\n",
    "\n",
    "# Save the trained model and tokenizer\n",
    "model.save_pretrained(output_dir)\n",
    "print(\"Model saved successfully at:\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_dir = \"./saved_model\"\n",
    "\n",
    "# Load the model and tokenizer\n",
    "loaded_model = GPT2LMHeadModel.from_pretrained(saved_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/orchid/anaconda3/envs/tf_gpu/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "# Define the input text and summary\n",
    "from datasets import load_metric\n",
    "o = 5\n",
    "input_text = list(test_data['Text'][o:o+1])[0]\n",
    "reference_summary = list(test_data['Summary'][o:o+1])[0]\n",
    "\n",
    "# Encode input text\n",
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "input_ids = input_ids.to(loaded_model.device)\n",
    "\n",
    "# Generate summary\n",
    "summary_ids = loaded_model.generate(input_ids, max_length=150, num_return_sequences=1, early_stopping=True)\n",
    "\n",
    "# Decode the generated summary\n",
    "generated_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# Compute ROUGE score\n",
    "rouge_metric = load_metric(\"rouge\")\n",
    "predictions = [generated_summary]\n",
    "references = [reference_summary]\n",
    "rouge_results = rouge_metric.compute(predictions=predictions, references=references)\n",
    "\n",
    "# Print the input text, reference summary, generated summary, and ROUGE scores\n",
    "print(\"Given Review Text:\")\n",
    "print(input_text)\n",
    "print(\"\\nGiven Summary:\")\n",
    "print(reference_summary)\n",
    "print(\"\\nGenerated Summary:\")\n",
    "print(generated_summary)\n",
    "print(\"\\nROUGE Scores:\")\n",
    "print(f\"ROUGE-1: Precision: {rouge_results['rouge1'].mid.precision:.2f}, Recall: {rouge_results['rouge1'].mid.recall:.2f}, F1-Score: {rouge_results['rouge1'].mid.fmeasure:.2f}\")\n",
    "print(f\"ROUGE-2: Precision: {rouge_results['rouge2'].mid.precision:.2f}, Recall: {rouge_results['rouge2'].mid.recall:.2f}, F1-Score: {rouge_results['rouge2'].mid.fmeasure:.2f}\")\n",
    "print(f\"ROUGE-L: Precision: {rouge_results['rougeL'].mid.precision:.2f}, Recall: {rouge_results['rougeL'].mid.recall:.2f}, F1-Score: {rouge_results['rougeL'].mid.fmeasure:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm always on the lookout for soda's that are ...</td>\n",
       "      <td>Soda Substitute that tastes Similar to the Ori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PopChips are the best potato chips I have ever...</td>\n",
       "      <td>The Barbecue are my favorite chips!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I ordered these after hearing about them from ...</td>\n",
       "      <td>VERY cool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is the first K-cup and Tea product from T...</td>\n",
       "      <td>Twinings Earl Grey Tea K-Cups</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My dog loves these and I feel good about givin...</td>\n",
       "      <td>Great organic dog treat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  I'm always on the lookout for soda's that are ...   \n",
       "1  PopChips are the best potato chips I have ever...   \n",
       "2  I ordered these after hearing about them from ...   \n",
       "3  This is the first K-cup and Tea product from T...   \n",
       "4  My dog loves these and I feel good about givin...   \n",
       "\n",
       "                                             Summary  \n",
       "0  Soda Substitute that tastes Similar to the Ori...  \n",
       "1              The Barbecue are my favorite chips!!!  \n",
       "2                                          VERY cool  \n",
       "3                      Twinings Earl Grey Tea K-Cups  \n",
       "4                            Great organic dog treat  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = test_data.reset_index(drop =True)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/orchid/anaconda3/envs/tf_gpu/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/rouge/rouge.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROUGE-1 Score: 0.018875613807350887\n",
      "Average ROUGE-2 Score: 0.0010336532287751798\n",
      "Average ROUGE-L Score: 0.01862561380735089\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "# Load ROUGE metric\n",
    "rouge_metric = load_metric(\"rouge\")\n",
    "\n",
    "# Initialize lists to store ROUGE scores\n",
    "rouge1_scores = []\n",
    "rouge2_scores = []\n",
    "rougeL_scores = []\n",
    "\n",
    "# Iterate through test dataset\n",
    "for idx in range(len(test_data[0:100])):\n",
    "    example = test_data['Text'][idx]\n",
    "    \n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "    input_ids = input_ids.to(loaded_model.device)\n",
    "\n",
    "# Generate summary\n",
    "    summary_ids = model.generate(input_ids, max_length=100, num_return_sequences=1, early_stopping=True)\n",
    "\n",
    "# Decode the generated summary\n",
    "    generated_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Compute ROUGE scores\n",
    "    reference_summary = test_data['Summary'][idx]\n",
    "    rouge_results = rouge_metric.compute(predictions=[generated_summary], references=[reference_summary])\n",
    "\n",
    "    # Store ROUGE scores\n",
    "    rouge1_scores.append(rouge_results['rouge1'].mid.fmeasure)\n",
    "    rouge2_scores.append(rouge_results['rouge2'].mid.fmeasure)\n",
    "    rougeL_scores.append(rouge_results['rougeL'].mid.fmeasure)\n",
    "\n",
    "# Compute average ROUGE scores\n",
    "avg_rouge1 = sum(rouge1_scores) / len(rouge1_scores)\n",
    "avg_rouge2 = sum(rouge2_scores) / len(rouge2_scores)\n",
    "avg_rougeL = sum(rougeL_scores) / len(rougeL_scores)\n",
    "\n",
    "# Print average ROUGE scores\n",
    "print(\"Average ROUGE-1 Score:\", avg_rouge1)\n",
    "print(\"Average ROUGE-2 Score:\", avg_rouge2)\n",
    "print(\"Average ROUGE-L Score:\", avg_rougeL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validating using the summarization using the Pre-Trained GPT-2 without Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text:\n",
      "My dog loves these and I feel good about giving them to her since they're organic. When I first opened the package, I thought the treats were a little too large for my small dog, but was happy to see that they're scored and fairly easy to break in two. If I had any complaints, it would be that the treats are extremely hard and are a little bit difficult for my 15 year old dog to eat.\n",
      "Generated Summary:\n",
      "My dog loves these and I feel good about giving them to her since they're organic. When I first opened the package, I thought the treats were a little too large for my small dog, but was happy to see that they're scored and fairly easy to break in two. If I had any complaints, it would be that the treats are extremely hard and are a little bit difficult for my 15 year old dog to eat. I'm not sure if I would have bought them if I had a larger dog, but I'm sure they would have been a little bit easier to chew on. I'm not sure if I would have bought them if I had a larger dog, but I'm sure they would have been a little bit easier to chew\n",
      "\n",
      "ROUGE Score:\n",
      "{'rouge1': AggregateScore(low=Score(precision=1.0, recall=0.5673758865248227, fmeasure=0.7239819004524888), mid=Score(precision=1.0, recall=0.5673758865248227, fmeasure=0.7239819004524888), high=Score(precision=1.0, recall=0.5673758865248227, fmeasure=0.7239819004524888)), 'rouge2': AggregateScore(low=Score(precision=1.0, recall=0.5642857142857143, fmeasure=0.7214611872146118), mid=Score(precision=1.0, recall=0.5642857142857143, fmeasure=0.7214611872146118), high=Score(precision=1.0, recall=0.5642857142857143, fmeasure=0.7214611872146118)), 'rougeL': AggregateScore(low=Score(precision=1.0, recall=0.5673758865248227, fmeasure=0.7239819004524888), mid=Score(precision=1.0, recall=0.5673758865248227, fmeasure=0.7239819004524888), high=Score(precision=1.0, recall=0.5673758865248227, fmeasure=0.7239819004524888)), 'rougeLsum': AggregateScore(low=Score(precision=1.0, recall=0.5673758865248227, fmeasure=0.7239819004524888), mid=Score(precision=1.0, recall=0.5673758865248227, fmeasure=0.7239819004524888), high=Score(precision=1.0, recall=0.5673758865248227, fmeasure=0.7239819004524888))}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/orchid/anaconda3/envs/tf_gpu/lib/python3.9/site-packages/datasets/load.py:756: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/rouge/rouge.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from datasets import load_metric\n",
    "import torch\n",
    "\n",
    "# Load the pre-trained model and tokenizer\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Define the input text\n",
    "input_text = \"My dog loves these and I feel good about giving them to her since they're organic. When I first opened the package, I thought the treats were a little too large for my small dog, but was happy to see that they're scored and fairly easy to break in two. If I had any complaints, it would be that the treats are extremely hard and are a little bit difficult for my 15 year old dog to eat.\"\n",
    "\n",
    "# Tokenize the input text\n",
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "\n",
    "# Generate summary\n",
    "summary_ids = model.generate(input_ids, max_length=150, num_return_sequences=1, early_stopping=True)\n",
    "\n",
    "# Decode the generated summary\n",
    "generated_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "print(\"Input Text:\")\n",
    "print(input_text)\n",
    "# Print the generated summary\n",
    "print(\"Generated Summary:\")\n",
    "print(generated_summary)\n",
    "\n",
    "# Compute ROUGE score\n",
    "rouge_metric = load_metric(\"rouge\")\n",
    "\n",
    "# Define the reference and predicted summaries\n",
    "references = [generated_summary]\n",
    "predictions = [input_text]\n",
    "\n",
    "# Compute ROUGE score\n",
    "rouge_results = rouge_metric.compute(predictions=predictions, references=references)\n",
    "\n",
    "# Print the ROUGE score\n",
    "print(\"\\nROUGE Score:\")\n",
    "print(rouge_results)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
